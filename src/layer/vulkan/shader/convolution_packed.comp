// Copyright 2026 Tencent
// SPDX-License-Identifier: BSD-3-Clause

#version 450

#extension GL_GOOGLE_include_directive : enable
#include "vulkan_activation.comp"

layout(constant_id = 0) const int kernel_w = 1;
layout(constant_id = 1) const int kernel_h = 1;
layout(constant_id = 2) const int dilation_w = 1;
layout(constant_id = 3) const int dilation_h = 1;
layout(constant_id = 4) const int stride_w = 1;
layout(constant_id = 5) const int stride_h = 1;
layout(constant_id = 6) const int bias_term = 0;
layout(constant_id = 7) const int activation_type = 0;
layout(constant_id = 8) const float activation_param_0 = 0;
layout(constant_id = 9) const float activation_param_1 = 0;
layout(constant_id = 10) const int elempack = 1;
layout(constant_id = 11) const int out_elempack = 1;

#define shape_constant_id_offset 12
layout(constant_id = shape_constant_id_offset + 0) const int dims = 0;
layout(constant_id = shape_constant_id_offset + 1) const int w = 0;
layout(constant_id = shape_constant_id_offset + 2) const int h = 0;
layout(constant_id = shape_constant_id_offset + 3) const int c = 0;
layout(constant_id = shape_constant_id_offset + 4) const int cstep = 0;

layout(constant_id = shape_constant_id_offset + 5) const int outdims = 0;
layout(constant_id = shape_constant_id_offset + 6) const int outw = 0;
layout(constant_id = shape_constant_id_offset + 7) const int outh = 0;
layout(constant_id = shape_constant_id_offset + 8) const int outc = 0;
layout(constant_id = shape_constant_id_offset + 9) const int outcstep = 0;

layout(constant_id = shape_constant_id_offset + 10) const int num_output = 0;

// scalar view  (for pack1 input/output access)
layout(binding = 0) readonly buffer bottom_blob_1 { sfp bottom_blob_data_1[]; };
layout(binding = 1) writeonly buffer top_blob_1 { sfp top_blob_data_1[]; };

// vec4 view  (for pack4 input/output access, weight/bias always vec4)
layout(binding = 2) readonly buffer bottom_blob_4 { sfpvec4 bottom_blob_data_4[]; };
layout(binding = 3) writeonly buffer top_blob_4 { sfpvec4 top_blob_data_4[]; };
layout(binding = 4) readonly buffer weight_blob { sfpvec4 weight_data[]; };
layout(binding = 5) readonly buffer bias_blob { sfpvec4 bias_data[]; };

layout(push_constant) uniform parameter
{
    int dims;
    int w;
    int h;
    int c;
    int cstep;

    int outdims;
    int outw;
    int outh;
    int outc;
    int outcstep;

    int num_output;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x) * 2;
    int gy = int(gl_GlobalInvocationID.y) * 2;
    int gz = int(gl_GlobalInvocationID.z) * 2;

    if (gx >= psc(outw) || gy >= psc(outh) || gz >= psc(outc))
        return;

    const ivec2 gx2 = gx + ivec2(0, 1);
    const ivec2 gy2 = gy + ivec2(0, 1);
    const ivec2 gz2 = gz + ivec2(0, 1);

    afpvec4 sum0;
    afpvec4 sum1;
    afpvec4 sum2;
    afpvec4 sum3;
    afpvec4 sum4;
    afpvec4 sum5;
    afpvec4 sum6;
    afpvec4 sum7;

    if (bias_term == 1)
    {
        // bias is always packed as vec4
        sum0 = buffer_ld4(bias_data, gz2.x);
        sum4 = buffer_ld4(bias_data, gz2.y);
        sum1 = sum0;
        sum2 = sum0;
        sum3 = sum0;
        sum5 = sum4;
        sum6 = sum4;
        sum7 = sum4;
    }
    else
    {
        sum0 = afpvec4(0.f);
        sum1 = afpvec4(0.f);
        sum2 = afpvec4(0.f);
        sum3 = afpvec4(0.f);
        sum4 = afpvec4(0.f);
        sum5 = afpvec4(0.f);
        sum6 = afpvec4(0.f);
        sum7 = afpvec4(0.f);
    }

    // weight layout: (maxk, c, outc_pack4), each element is 4*elempack floats
    // when elempack=4: w_offset indexes mat4 (16 floats)
    // when elempack=1: w_offset indexes vec4 (4 floats)
    ivec2 w_offset = gz2 * psc(c) * kernel_w * kernel_h;

    for (int z = 0; z < psc(c); z++)
    {
        ivec4 v_offset;
        v_offset.rg = z * psc(cstep) + gy2.x * stride_h * psc(w) + gx2 * stride_w;
        v_offset.ba = z * psc(cstep) + gy2.y * stride_h * psc(w) + gx2 * stride_w;

        for (int y = 0; y < kernel_h; y++)
        {
            for (int x = 0; x < kernel_w; x++)
            {
                if (elempack == 4)
                {
                    afpvec4 v0 = buffer_ld4(bottom_blob_data_4, v_offset.r + x * dilation_w);
                    afpvec4 v1 = buffer_ld4(bottom_blob_data_4, v_offset.g + x * dilation_w);
                    afpvec4 v2 = buffer_ld4(bottom_blob_data_4, v_offset.b + x * dilation_w);
                    afpvec4 v3 = buffer_ld4(bottom_blob_data_4, v_offset.a + x * dilation_w);

                    // weight is 4x4 mat, load from 4 consecutive vec4
                    afpmat4 k0 = afpmat4(
                        buffer_ld4(weight_data, (w_offset.x + x) * 4 + 0),
                        buffer_ld4(weight_data, (w_offset.x + x) * 4 + 1),
                        buffer_ld4(weight_data, (w_offset.x + x) * 4 + 2),
                        buffer_ld4(weight_data, (w_offset.x + x) * 4 + 3));
                    afpmat4 k1 = afpmat4(
                        buffer_ld4(weight_data, (w_offset.y + x) * 4 + 0),
                        buffer_ld4(weight_data, (w_offset.y + x) * 4 + 1),
                        buffer_ld4(weight_data, (w_offset.y + x) * 4 + 2),
                        buffer_ld4(weight_data, (w_offset.y + x) * 4 + 3));

                    sum0 += v0 * k0;
                    sum1 += v1 * k0;
                    sum2 += v2 * k0;
                    sum3 += v3 * k0;
                    sum4 += v0 * k1;
                    sum5 += v1 * k1;
                    sum6 += v2 * k1;
                    sum7 += v3 * k1;
                }
                else // elempack == 1
                {
                    afp v0 = buffer_ld1(bottom_blob_data_1, v_offset.r + x * dilation_w);
                    afp v1 = buffer_ld1(bottom_blob_data_1, v_offset.g + x * dilation_w);
                    afp v2 = buffer_ld1(bottom_blob_data_1, v_offset.b + x * dilation_w);
                    afp v3 = buffer_ld1(bottom_blob_data_1, v_offset.a + x * dilation_w);

                    // weight is vec4 (4 output channels per input channel)
                    afpvec4 k0 = buffer_ld4(weight_data, w_offset.x + x);
                    afpvec4 k1 = buffer_ld4(weight_data, w_offset.y + x);

                    sum0 += v0 * k0;
                    sum1 += v1 * k0;
                    sum2 += v2 * k0;
                    sum3 += v3 * k0;
                    sum4 += v0 * k1;
                    sum5 += v1 * k1;
                    sum6 += v2 * k1;
                    sum7 += v3 * k1;
                }
            }

            v_offset += dilation_h * psc(w);
            w_offset += kernel_w;
        }
    }

    sum0 = activation_afpvec4(sum0, activation_type, activation_param_0, activation_param_1);
    sum1 = activation_afpvec4(sum1, activation_type, activation_param_0, activation_param_1);
    sum2 = activation_afpvec4(sum2, activation_type, activation_param_0, activation_param_1);
    sum3 = activation_afpvec4(sum3, activation_type, activation_param_0, activation_param_1);
    sum4 = activation_afpvec4(sum4, activation_type, activation_param_0, activation_param_1);
    sum5 = activation_afpvec4(sum5, activation_type, activation_param_0, activation_param_1);
    sum6 = activation_afpvec4(sum6, activation_type, activation_param_0, activation_param_1);
    sum7 = activation_afpvec4(sum7, activation_type, activation_param_0, activation_param_1);

    if (out_elempack == 4)
    {
        // outcstep is in vec4 units
        const ivec2 gi = gz2 * psc(outcstep) + gy * psc(outw) + gx;

        buffer_st4(top_blob_data_4, gi.x, sum0);
        if (gx + 1 < psc(outw)) buffer_st4(top_blob_data_4, gi.x + 1, sum1);
        if (gy + 1 < psc(outh)) buffer_st4(top_blob_data_4, gi.x + psc(outw), sum2);
        if (gy + 1 < psc(outh) && gx + 1 < psc(outw)) buffer_st4(top_blob_data_4, gi.x + psc(outw) + 1, sum3);
        if (gz + 1 < psc(outc))
        {
            buffer_st4(top_blob_data_4, gi.y, sum4);
            if (gx + 1 < psc(outw)) buffer_st4(top_blob_data_4, gi.y + 1, sum5);
            if (gy + 1 < psc(outh)) buffer_st4(top_blob_data_4, gi.y + psc(outw), sum6);
            if (gy + 1 < psc(outh) && gx + 1 < psc(outw)) buffer_st4(top_blob_data_4, gi.y + psc(outw) + 1, sum7);
        }
    }
    else // out_elempack == 1
    {
        // outcstep is 4 * scalar_cstep in scalar units
        // each pack4 group spans 4 scalar channels
        const int channel_step = psc(outcstep) / 4;
        const ivec2 gi = gz2 * psc(outcstep) + gy * psc(outw) + gx;

        // channel indices for gz2
        const ivec2 base_ch = gz2 * 4;
        const int nout = psc(num_output);

        // write 4 channels from sum0, guard out-of-bounds channels
        buffer_st1(top_blob_data_1, gi.x, sum0.r);
        if (base_ch.x + 1 < nout) buffer_st1(top_blob_data_1, gi.x + channel_step, sum0.g);
        if (base_ch.x + 2 < nout) buffer_st1(top_blob_data_1, gi.x + channel_step * 2, sum0.b);
        if (base_ch.x + 3 < nout) buffer_st1(top_blob_data_1, gi.x + channel_step * 3, sum0.a);

        if (gx + 1 < psc(outw))
        {
            buffer_st1(top_blob_data_1, gi.x + 1, sum1.r);
            if (base_ch.x + 1 < nout) buffer_st1(top_blob_data_1, gi.x + 1 + channel_step, sum1.g);
            if (base_ch.x + 2 < nout) buffer_st1(top_blob_data_1, gi.x + 1 + channel_step * 2, sum1.b);
            if (base_ch.x + 3 < nout) buffer_st1(top_blob_data_1, gi.x + 1 + channel_step * 3, sum1.a);
        }
        if (gy + 1 < psc(outh))
        {
            int gi2 = gi.x + psc(outw);
            buffer_st1(top_blob_data_1, gi2, sum2.r);
            if (base_ch.x + 1 < nout) buffer_st1(top_blob_data_1, gi2 + channel_step, sum2.g);
            if (base_ch.x + 2 < nout) buffer_st1(top_blob_data_1, gi2 + channel_step * 2, sum2.b);
            if (base_ch.x + 3 < nout) buffer_st1(top_blob_data_1, gi2 + channel_step * 3, sum2.a);
        }
        if (gy + 1 < psc(outh) && gx + 1 < psc(outw))
        {
            int gi3 = gi.x + psc(outw) + 1;
            buffer_st1(top_blob_data_1, gi3, sum3.r);
            if (base_ch.x + 1 < nout) buffer_st1(top_blob_data_1, gi3 + channel_step, sum3.g);
            if (base_ch.x + 2 < nout) buffer_st1(top_blob_data_1, gi3 + channel_step * 2, sum3.b);
            if (base_ch.x + 3 < nout) buffer_st1(top_blob_data_1, gi3 + channel_step * 3, sum3.a);
        }
        if (gz + 1 < psc(outc))
        {
            if (base_ch.y < nout) buffer_st1(top_blob_data_1, gi.y, sum4.r);
            if (base_ch.y + 1 < nout) buffer_st1(top_blob_data_1, gi.y + channel_step, sum4.g);
            if (base_ch.y + 2 < nout) buffer_st1(top_blob_data_1, gi.y + channel_step * 2, sum4.b);
            if (base_ch.y + 3 < nout) buffer_st1(top_blob_data_1, gi.y + channel_step * 3, sum4.a);

            if (gx + 1 < psc(outw))
            {
                if (base_ch.y < nout) buffer_st1(top_blob_data_1, gi.y + 1, sum5.r);
                if (base_ch.y + 1 < nout) buffer_st1(top_blob_data_1, gi.y + 1 + channel_step, sum5.g);
                if (base_ch.y + 2 < nout) buffer_st1(top_blob_data_1, gi.y + 1 + channel_step * 2, sum5.b);
                if (base_ch.y + 3 < nout) buffer_st1(top_blob_data_1, gi.y + 1 + channel_step * 3, sum5.a);
            }
            if (gy + 1 < psc(outh))
            {
                int gi6 = gi.y + psc(outw);
                if (base_ch.y < nout) buffer_st1(top_blob_data_1, gi6, sum6.r);
                if (base_ch.y + 1 < nout) buffer_st1(top_blob_data_1, gi6 + channel_step, sum6.g);
                if (base_ch.y + 2 < nout) buffer_st1(top_blob_data_1, gi6 + channel_step * 2, sum6.b);
                if (base_ch.y + 3 < nout) buffer_st1(top_blob_data_1, gi6 + channel_step * 3, sum6.a);
            }
            if (gy + 1 < psc(outh) && gx + 1 < psc(outw))
            {
                int gi7 = gi.y + psc(outw) + 1;
                if (base_ch.y < nout) buffer_st1(top_blob_data_1, gi7, sum7.r);
                if (base_ch.y + 1 < nout) buffer_st1(top_blob_data_1, gi7 + channel_step, sum7.g);
                if (base_ch.y + 2 < nout) buffer_st1(top_blob_data_1, gi7 + channel_step * 2, sum7.b);
                if (base_ch.y + 3 < nout) buffer_st1(top_blob_data_1, gi7 + channel_step * 3, sum7.a);
            }
        }
    }
}
